import os
import re
import time
import pandas as pd
from collections import Counter
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from dotenv import load_dotenv
import pymorphy3

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
groups_file = os.getenv("VK_GROUPS_FILE", "Lists 640.xlsx")

# –ß–∏—Ç–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ—Å—Ç–≤ –∏–∑ Excel (—Å—Ç–æ–ª–±–µ—Ü –ê)
df_groups = pd.read_excel(groups_file)
groups = df_groups.iloc[:, 0].dropna().astype(str).tolist()

print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(groups)} —Å–æ–æ–±—â–µ—Å—Ç–≤ –∏–∑ '{groups_file}'")

# –ú–æ—Ä—Ñ–æ–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ª–æ–≤
morph = pymorphy3.MorphAnalyzer()

def normalize_word(word: str) -> str:
    return morph.parse(word)[0].normal_form

def extract_phrases(text: str, n: int = 2):
    """–ò–∑–≤–ª–µ–∫–∞–µ–º –±–∏–≥—Ä–∞–º–º—ã –∏ —Ç—Ä–∏–≥—Ä–∞–º–º—ã"""
    words = re.findall(r"[–∞-—èa-z—ë]+", text.lower())
    stop = {"–∏","–≤","–Ω–∞","—Å","–ø–æ","–∞","–Ω–æ","–∏–ª–∏","–∫–∞–∫","–∫","—á—Ç–æ","—ç—Ç–æ","–æ—Ç","–¥–ª—è","–∏–∑","–ø–æ–¥","–ø—Ä–∏","–Ω–∞–¥","—É","–∂–µ","–±—ã","—Ç–æ"}
    words = [normalize_word(w) for w in words if w not in stop and len(w) > 2]
    return [" ".join(words[i:i+n]) for i in range(len(words)-n+1)]

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Selenium
options = webdriver.ChromeOptions()
options.add_argument("--headless")
options.add_argument("--disable-blink-features=AutomationControlled")
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

all_phrases = Counter()

for g in groups:
    g = g.strip()
    if not g:
        continue

    try:
        url = f"https://vk.com/{g}"
        driver.get(url)
        time.sleep(2)

        texts = []

        # –ù–∞–∑–≤–∞–Ω–∏–µ
        try:
            title = driver.find_element(By.CLASS_NAME, "page_name").text
            texts.append(title)
        except:
            pass

        # –û–ø–∏—Å–∞–Ω–∏–µ
        try:
            desc = driver.find_element(By.CLASS_NAME, "page_description").text
            texts.append(desc)
        except:
            pass

        # –ü–æ—Å—Ç—ã
        posts = driver.find_elements(By.CLASS_NAME, "wall_post_text")
        for p in posts[:20]:  # –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 20 –ø–æ—Å—Ç–æ–≤
            texts.append(p.text)

        # –¢–æ–≤–∞—Ä—ã
        goods = driver.find_elements(By.CLASS_NAME, "market_row")
        for item in goods[:10]:  # –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 10 —Ç–æ–≤–∞—Ä–æ–≤
            texts.append(item.text)

        full_text = " ".join(texts)

        # –°—á–∏—Ç–∞–µ–º –±–∏–≥—Ä–∞–º–º—ã –∏ —Ç—Ä–∏–≥—Ä–∞–º–º—ã
        for n in [2, 3]:
            all_phrases.update(extract_phrases(full_text, n))

        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ: {g}")

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å {g}: {e}")

driver.quit()

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¢–û–ü-500 –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
df = pd.DataFrame(all_phrases.most_common(500), columns=["–§—Ä–∞–∑–∞", "–ß–∞—Å—Ç–æ—Ç–∞"])
df.to_csv("vk_keywords_from_groups.csv", index=False, encoding="utf-8-sig")

print("\nüî• –¢–û–ü-30 –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑:")
for phrase, count in all_phrases.most_common(30):
    print(f"{phrase} ‚Äî {count}")
